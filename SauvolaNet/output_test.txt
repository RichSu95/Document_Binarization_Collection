2021-10-18 03:18:26.211602: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-18 03:18:29.263237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10419 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1
2021-10-18 03:18:31.659274: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2021-10-18 03:18:34.609316: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8202
2021-10-18 03:18:36.088920: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
/home/woody/iwi5/iwi5033h/temp/sauvola/lib/python3.6/site-packages/keras/layers/core.py:1045: UserWarning: modelUtils is not loaded, but a Lambda layer uses it. It may cause errors.
  , UserWarning)
2.6.0
Model: "Sauvola_v3_att_w3.5.7.11.15.19_k0_R0_a0_bnorm"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
img01_inp (InputLayer)          [(None, None, None,  0                                            
__________________________________________________________________________________________________
conv0 (Conv2D)                  (None, None, None, 1 130         img01_inp[0][0]                  
__________________________________________________________________________________________________
inorm0 (InstanceNormalization)  (None, None, None, 1 0           conv0[0][0]                      
__________________________________________________________________________________________________
relu0 (Activation)              (None, None, None, 1 0           inorm0[0][0]                     
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, None, None, 1 2006        relu0[0][0]                      
__________________________________________________________________________________________________
inorm1 (InstanceNormalization)  (None, None, None, 1 0           conv1[0][0]                      
__________________________________________________________________________________________________
relu1 (Activation)              (None, None, None, 1 0           inorm1[0][0]                     
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, None, None, 2 3234        relu1[0][0]                      
__________________________________________________________________________________________________
inorm2 (InstanceNormalization)  (None, None, None, 2 0           conv2[0][0]                      
__________________________________________________________________________________________________
relu2 (Activation)              (None, None, None, 2 0           inorm2[0][0]                     
__________________________________________________________________________________________________
conv3 (Conv2D)                  (None, None, None, 2 4750        relu2[0][0]                      
__________________________________________________________________________________________________
inorm3 (InstanceNormalization)  (None, None, None, 2 0           conv3[0][0]                      
__________________________________________________________________________________________________
relu3 (Activation)              (None, None, None, 2 0           inorm3[0][0]                     
__________________________________________________________________________________________________
conv4 (Conv2D)                  (None, None, None, 2 6554        relu3[0][0]                      
__________________________________________________________________________________________________
inorm4 (InstanceNormalization)  (None, None, None, 2 0           conv4[0][0]                      
__________________________________________________________________________________________________
relu4 (Activation)              (None, None, None, 2 0           inorm4[0][0]                     
__________________________________________________________________________________________________
conv5 (Conv2D)                  (None, None, None, 3 8646        relu4[0][0]                      
__________________________________________________________________________________________________
inorm5 (InstanceNormalization)  (None, None, None, 3 0           conv5[0][0]                      
__________________________________________________________________________________________________
relu5 (Activation)              (None, None, None, 3 0           inorm5[0][0]                     
__________________________________________________________________________________________________
conv6 (Conv2D)                  (None, None, None, 3 11026       relu5[0][0]                      
__________________________________________________________________________________________________
inorm6 (InstanceNormalization)  (None, None, None, 3 0           conv6[0][0]                      
__________________________________________________________________________________________________
relu6 (Activation)              (None, None, None, 3 0           inorm6[0][0]                     
__________________________________________________________________________________________________
conv_att (Conv2D)               (None, None, None, 1 4342        relu6[0][0]                      
__________________________________________________________________________________________________
time1 (Permute)                 (None, 13, None, Non 0           conv_att[0][0]                   
__________________________________________________________________________________________________
sauvola (SauvolaMultiWindow)    (None, 13, None, Non 26          img01_inp[0][0]                  
__________________________________________________________________________________________________
attention (Lambda)              (None, None, None, 1 0           time1[0][0]                      
                                                                 sauvola[0][0]                    
__________________________________________________________________________________________________
difference_thresh (DifferenceTh (None, None, None, 1 1           img01_inp[0][0]                  
                                                                 attention[0][0]                  
==================================================================================================
Total params: 40,715
Trainable params: 40,715
Non-trainable params: 0
__________________________________________________________________________________________________
(1, 191, 245, 1)
(1, 191, 245, 1)
[[2.3085701  2.572113   2.4179027  ... 2.567046   2.6888778  2.6676447 ]
 [2.5271244  2.1149683  3.937494   ... 3.5637221  4.039414   4.0527873 ]
 [2.2170866  2.8577802  4.763805   ... 2.7866738  3.4477928  3.0077693 ]
 ...
 [1.9140594  1.7763127  1.9252789  ... 2.4278762  2.3476152  0.44851938]
 [2.1146858  2.175237   2.3413787  ... 2.6596363  2.7570958  0.98773444]
 [2.7170856  3.0778031  2.3787763  ... 2.0703897  2.104733   1.3541529 ]]
(1, 192, 624, 1)
(1, 192, 624, 1)
[[3.2152855 3.29814   3.342405  ... 2.8572078 3.0545292 2.8268168]
 [2.7213876 2.46606   3.455325  ... 3.951517  5.00657   3.780877 ]
 [2.6121955 2.9173603 3.8535967 ... 3.2213607 3.497737  3.3691661]
 ...
 [2.1893396 2.5522885 2.880076  ... 3.1123173 2.950909  4.588455 ]
 [2.0628119 2.342019  2.5660014 ... 2.992353  2.3568685 3.862816 ]
 [2.1539278 2.5517952 2.5057156 ... 2.833437  2.5723236 3.7745383]]
(1, 517, 1150, 1)
(1, 517, 1150, 1)
[[ 2.1244676   0.05304574  0.6931326  ...  2.5768507   2.462041
   2.6837943 ]
 [ 2.458427    1.5384307   0.69164187 ...  2.736389    2.1567197
   2.8181484 ]
 [ 2.4643307   1.2983376   0.41462487 ...  2.5651371   2.1133082
   2.7008967 ]
 ...
 [ 2.606222   -0.35049474 -0.4863587  ...  2.063815    1.9680895
   2.6135201 ]
 [ 2.153528   -0.8574415  -1.2127188  ...  2.171283    1.9978411
   2.77532   ]
 [ 2.853712   -0.2797401  -0.77671397 ...  1.9592152   2.1403034
   2.9461327 ]]
(1, 571, 898, 1)
(1, 571, 898, 1)
[[2.439656  1.7561605 2.2565112 ... 2.3799312 2.3343604 2.3645248]
 [2.3536808 1.6457396 2.3310575 ... 2.5405552 2.3212156 2.5498526]
 [2.0975037 1.7357249 2.533366  ... 2.2806861 2.0030298 2.2339218]
 ...
 [1.7740089 1.7845063 1.596272  ... 1.8428912 1.9071655 2.4367883]
 [1.6816704 2.076596  1.9982294 ... 1.7764069 1.8736697 2.4480553]
 [2.1911175 2.3188663 1.9718661 ... 1.8149068 1.9317565 2.2114694]]
(1, 393, 462, 1)
(1, 393, 462, 1)
[[1.463121  1.8907706 1.3856324 ... 1.8229358 2.2488828 1.9199015]
 [1.4768302 1.3860812 1.7987379 ... 2.423641  3.4231956 2.4670975]
 [1.7282373 1.2434992 2.4776132 ... 2.4427989 3.141685  2.8347037]
 ...
 [1.9313773 2.4899056 3.1047513 ... 2.7921946 2.63114   3.2757463]
 [1.7781354 2.36894   2.6676621 ... 2.2867892 2.233869  3.0460956]
 [2.4026804 2.605754  2.69906   ... 2.309774  2.433059  3.1387906]]
(1, 289, 1132, 1)
(1, 289, 1132, 1)
[[2.4053493  2.2708418  2.7006688  ... 2.2349503  2.2020302  2.4158132 ]
 [2.1005683  2.3477292  2.307189   ... 2.53839    2.119639   2.4532928 ]
 [1.617103   1.5213237  0.23208527 ... 2.2817993  2.0089574  2.257551  ]
 ...
 [1.8783047  2.2588143  1.9179707  ... 1.7340885  2.443245   2.7954385 ]
 [1.8266406  2.2218616  1.9022944  ... 1.6932199  2.6287982  2.9615083 ]
 [2.0106022  2.0353224  2.114214   ... 1.2699033  2.4684687  3.0808706 ]]
(1, 304, 542, 1)
(1, 304, 542, 1)
[[2.8093982 2.6264212 2.816132  ... 2.6280925 2.6222224 2.8112776]
 [2.9839725 2.5249379 5.175506  ... 3.9603553 3.9473627 3.5065446]
 [2.3826199 2.4135969 3.618212  ... 3.327175  3.5053296 3.301892 ]
 ...
 [2.2694016 2.6502705 3.175309  ... 3.3297002 3.1820107 3.3562233]
 [2.1336272 2.4125528 2.7171407 ... 2.4817715 2.2238398 2.562391 ]
 [2.5856097 3.0233545 2.8407166 ... 2.5231767 2.4969285 2.9200327]]
(1, 1094, 1136, 1)
(1, 1094, 1136, 1)
[[2.4461746 2.4932842 3.0807793 ... 1.2608213 1.0701661 1.7872477]
 [1.7506334 2.3248892 2.9353418 ... 1.8415315 1.744842  2.3403094]
 [1.608833  1.6323586 1.8840543 ... 1.7073185 1.4653437 2.166119 ]
 ...
 [1.9961059 2.92332   3.284382  ... 1.5598778 1.5693301 2.0199008]
 [1.8782166 3.0299752 3.1396027 ... 1.5290799 1.6228384 2.2747612]
 [2.1375775 2.7270095 2.632357  ... 1.5840434 1.6070286 1.7795033]]
(1, 376, 535, 1)
(1, 376, 535, 1)
[[2.5417888 2.3287163 2.59856   ... 2.267982  2.3512058 2.456735 ]
 [3.0954206 2.580632  4.800131  ... 3.1779346 2.9761295 2.9541948]
 [2.3183136 2.4240797 3.0963142 ... 2.8867722 2.7841878 2.823921 ]
 ...
 [2.0956001 2.491742  2.8629174 ... 2.563953  2.5061908 3.1938784]
 [2.1509736 2.6321428 2.9948108 ... 2.7754655 2.6893547 3.313734 ]
 [2.3402886 2.7895443 2.6416519 ... 2.3197696 2.5030065 3.4749472]]
(1, 424, 1145, 1)
(1, 424, 1145, 1)
[[2.0456295 1.5912122 1.9291762 ... 2.1207783 2.134264  2.259634 ]
 [1.9409837 1.4995072 2.0246499 ... 1.8594862 1.8168681 2.0096767]
 [1.7003664 1.4894652 2.146739  ... 1.8794584 1.9707936 2.0383213]
 ...
 [1.7311778 1.7349508 2.2433743 ... 2.052562  2.2228642 2.1897204]
 [1.6370543 1.6090943 1.900818  ... 1.880444  1.9399811 1.909645 ]
 [1.9698188 1.5697466 1.8776853 ... 1.8235178 1.9174774 1.8080375]]
----------------------------------------------------------------------------------------------------
Total average : DIBCO2019 [ 0.64894347 13.95062995  0.64435705  8.28217164]
